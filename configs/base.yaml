seed: 42

model:
  name: "Qwen/Qwen2.5-Math-1.5B-Instruct"

data:
  dataset_name: "openai/gsm8k"  # Options: openai/gsm8k, HuggingFaceH4/openr1-math-220k

training:
  algo: "GRPO"  # Options: SFT, PPO, GRPO, DR.GRPO, GSPO, DAPO, GRPO-LEAD
  group_size: 8
  batch_size: 2
  epochs: 1
  learning_rate: 1.0e-5
  max_samples: 1000  # Set to null for full dataset
  ppo_epochs: 2  # Inner optimization loop iterations
  save_steps: 100  # Save checkpoint every N steps

paths:
  output_dir: "checkpoints"

logging:
  use_wandb: false
  project: "UnifiedRL"